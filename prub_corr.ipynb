{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"ttps://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gustavo_functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets (make sure to update the file paths if necessary)\n",
    "global_df = pd.read_csv(\"data-project3/GlobalLandTemperaturesByCity.csv\")\n",
    "pollution_df = pd.read_csv(\"data-project3/pollution_us_2000_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 1 Cleaning the GlobalLandTemperaturesByCity dataset\n",
    "# Filter only data for the United States\n",
    "global_df = global_df[global_df[\"Country\"] == \"United States\"].copy()\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "global_df[\"dt\"] = pd.to_datetime(global_df[\"dt\"])\n",
    "\n",
    "# Extract the year from the date column\n",
    "global_df[\"Year\"] = global_df[\"dt\"].dt.year\n",
    "\n",
    "# Remove NaN values in the temperature column\n",
    "global_df.dropna(subset=[\"AverageTemperature\"], inplace=True)\n",
    "\n",
    "# Group by city and year, calculating the annual average temperature\n",
    "global_clean = global_df.groupby([\"City\", \"Year\"])['AverageTemperature'].mean().reset_index()\n",
    "\n",
    "# Extract unique latitude values per city\n",
    "latitude_df = global_df[[\"City\", \"Latitude\",\"Longitude\"]].drop_duplicates()\n",
    "\n",
    "### 2 Cleaning the Greenhouse Gas dataset\n",
    "# Filter only \"United States of America\"\n",
    "#green_df = green_df[green_df[\"country_or_area\"] == \"United States of America\"].copy()\n",
    "\n",
    "### 3 Cleaning the Pollution dataset\n",
    "# Convert the date column to datetime format\n",
    "pollution_df[\"Date Local\"] = pd.to_datetime(pollution_df[\"Date Local\"])\n",
    "\n",
    "# Extract the year from the date column\n",
    "pollution_df[\"Year\"] = pollution_df[\"Date Local\"].dt.year\n",
    "\n",
    "# Select key columns\n",
    "pollution_clean = pollution_df[[\"City\", \"Year\", \"NO2 Mean\", \"SO2 Mean\", \"CO Mean\"]]\n",
    "\n",
    "# Average pollution values by city and year\n",
    "pollution_clean = pollution_clean.groupby([\"City\", \"Year\"]).mean().reset_index()\n",
    "\n",
    "###  Merging the datasets\n",
    "# Merge temperature and pollution data\n",
    "final_df = pd.merge(global_clean, pollution_clean, on=[\"City\", \"Year\"], how=\"inner\")\n",
    "\n",
    "\n",
    "# Drop the duplicate year column\n",
    "#final_df.drop(columns=[\"year\"], inplace=True)\n",
    "\n",
    "# Merge latitude data\n",
    "final_df = pd.merge(final_df, latitude_df, on=\"City\", how=\"left\")\n",
    "\n",
    "# Convert latitude values to numeric format\n",
    "final_df[\"Latitude\"] = final_df[\"Latitude\"].str.replace(\"N\", \"\").str.replace(\"S\", \"-\").astype(float)\n",
    "\n",
    "# Convert longitude to numeric format\n",
    "final_df[\"Longitude\"] = final_df[\"Longitude\"].apply(lambda x: float(x[:-1]) * (-1 if x[-1] == 'W' else 1))\n",
    "\n",
    "###\n",
    "final_df = final_df.rename(columns={'value': 'CO2-natural-pross'})\n",
    "\n",
    "# Save the cleaned and merged dataset in CSV format\n",
    "#final_df.to_csv(\"cleaned_temperature_pollution_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Mutual Information\n",
      "NO2 Mean            0.215682\n",
      "SO2 Mean            0.246242\n",
      "CO Mean             0.201956\n"
     ]
    }
   ],
   "source": [
    "# Compute mutual information between Temperature and Pollution variables\n",
    "X = df[[\"NO2 Mean\", \"SO2 Mean\", \"CO Mean\"]]\n",
    "y = df[\"AverageTemperature\"]\n",
    "\n",
    "my_scores = mutual_info_regression(X, y)\n",
    "my_df = pd.DataFrame(my_scores, index=X.columns, columns=[\"Mutual Information\"])\n",
    "print(my_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_intro_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
