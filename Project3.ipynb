{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature forecasting for different cities in the world\n",
    "\n",
    "## Introduction\n",
    "For this project you are asked to analyze three datasets, called respectively:\n",
    "1. pollution_us_2000_2016.csv\n",
    "2. greenhouse_gas_inventory_data_data.csv\n",
    "3. GlobalLandTemperaturesByCity.csv\n",
    "\n",
    "You are asked to extract from dataset 2 only the US countries (for which we have info in the other datasets) and to perform the following tasks:\n",
    "- to measure how pollution and temperature create cluster tracing the high populated cities in the world\n",
    "- to analyze the correlation between pollution data and temperature change.\n",
    "- to predict the yearly temperature change of a given city over a given time period, using the <b>ARIMA model</b> for <b>time series forecasting</b>, that is a model for time series forecasting integrating AR models with Moving Average.\n",
    "- (OPTIONAL) rank the 5 cities that will have a highest temperature change in US\n",
    "\n",
    "\n",
    "### TASK1 :Cluster Analysis\n",
    "You use K-means or DBSCAN to perform the cluster analysis, and create a new dataset where the cities are associated to the different identified clusters\n",
    "\n",
    "### TASK 2: Correlation Analysis\n",
    "\n",
    "You measure the correlation between:\n",
    "- temperature and latitude\n",
    "- temperature and pollution\n",
    "- temperature change (difference between the average temperature measured over the last 3 years and the previous temperature) and pollution\n",
    "\n",
    "\n",
    "### TASK 3: Predicting the Temperature of a Given City across a Specified Time Period\n",
    "After reading the data in the temperature data set, for each city cluster, before applying the ARIMA model you perform the following steps:\n",
    "\n",
    "- EDA\n",
    "- data cleaning and preprocessing (Converting the 'dt' (date) column to DateTime format, removing NaN)\n",
    "- feature selection\n",
    "- make the time-series stationary\n",
    "- check for stationarity : Calculating the Augmented Dickey-Fuller Test statistic \n",
    "- identify the (p, q) order of the ARIMA model using ACF partial autocorrelation plot\n",
    "\n",
    "Then:\n",
    "\n",
    "-fit the ARIMA model using the calculated p, q values.\n",
    "-calculate the MSE with respect to the true temp. measurements to estimate the performance of the model\n",
    "\n",
    "\n",
    "NOTE: ARIMA models need the data to be stationary i.e. the data must not exhibit trend and/or seasonality. To identify and remove trend and seasonality, we can use\n",
    "- seasonal decomposition\n",
    "- differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARMAResults\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file containing the polluters \n",
    "df_pollution = pd.read_csv#(\"cata/pollution_us_2000_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read the csv file containing temperature data into a DataFrame\n",
    "df_temp = pd.read_csv(\"data/GlobalLandTemperaturesByCity.csv\")\n",
    "\n",
    "city_df #city dataset with cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SECTION 3: ARIMA model for temperature forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although we can determine p, q values manually by looking at the ACF and PACF plots for a given city, we must automate the process\n",
    "#(OPTIONAL) To automate the process, we must perform a grid search over different values of p and q and choose the ARIMA model for which the AIC and BIC values are minimum\n",
    "\n",
    "p_range = q_range = list(range(0,#))  # taking values from 0 to # (decide this looking at PACF)\n",
    "\n",
    "aic_values = []\n",
    "bic_values = []\n",
    "pq_values = []\n",
    "\n",
    "for p in p_range:\n",
    "    for q in q_range:\n",
    "        try:\n",
    "            model = ARIMA(city_df, order=(p, d, q))\n",
    "            results = model.fit(disp=-1)\n",
    "            aic_values.append(ARMAResults.aic(results))\n",
    "            bic_values.append(ARMAResults.bic(results))\n",
    "            pq_values.append((p, q))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "best_pq = pq_values[aic_values.index(min(aic_values))]  # (p,q) corresponding to lowest AIC score\n",
    "print(\"(p,q) corresponding to lowest AIC score: \", best_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting an ARIMA model with chosen p, d, q values and calculating the mean squared error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "arima_model = ARIMA(city_df, order=(best_pq[0], 0, best_pq[1])).fit()\n",
    "predictions = arima_model.predict(start=0, end=len(city_df)-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "write here the report for the project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
